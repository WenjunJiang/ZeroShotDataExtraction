


#import vllm
import pandas as pd
import json
import ast
from openai import OpenAI


client = OpenAI(base_url="http://localhost:8000/v1", api_key="not-needed")

# list models
models = client.models.list()
print([m.id for m in models.data])

# simple chat completion
resp = client.chat.completions.create(
    model= "meta-llama/Llama-3.2-3B-Instruct",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "In one sentence, explain what vLLM is."},
    ],
    temperature=0.2,
    top_p=0.9,
    max_tokens=256,
    seed=777,
)
print(resp.choices[0].message.content)






llm = vllm.LLM(
    model='/kaggle/input/llama-3.2/transformers/3b-instruct/1',
    tensor_parallel_size=2, 
    gpu_memory_utilization=0.95, 
    trust_remote_code=True,
    dtype="half", 
    enforce_eager=True,
    #distributed_executor_backend="ray",
)
# tokenizer = llm.get_tokenizer()





system_prompt = "As a medical professional, please analyze the following medical notes carefully and extract relevant information in the specified JSON format. Do not include any values that are not mentioned in the notes."


# Define the template with a placeholder
prompt_template = """
For each entry:
- Accurately identify and extract patient data, visit motivation, symptoms, and vital signs.
- Only include keys that have corresponding information in the notes, omitting any keys that are not mentioned.
- Follow this JSON structure:

```json
{
  "patient_info": {
    "age": <number>,
    "gender": <string>
  },
  "visit_motivation": "",
  "symptoms": [<string>],
  "vital_signs": {
    "heart_rate": {
      "value": <number>,
      "unit": "bpm"
    },
    "oxygen_saturation": {
      "value": <number>,
      "unit": "%"
    },
    "cholesterol_level": {
      "value": <number>,
      "unit": "mg/dL"
    },
    "glucose_level": {
      "value": <number>,
      "unit": "mg/dL"
    },
    "temperature": {
      "value": <number>,
      "unit": "Â°C"
    },
    "respiratory_rate": {
      "value": <number>,
      "unit": "breaths/min"
    },
    "blood_pressure": {
      "systolic": {
        "value": <number>,
        "unit": "mmHg"
      },
      "diastolic": {
        "value": <number>,
        "unit": "mmHg"
      }
    }
  }
}

Here are the clinical notes to review:

{medical_notes}

"""


# load test data
test_df = pd.read_csv("/kaggle/input/medical-note-extraction-h-2-o-gen-ai-world-ny/test.csv")


test_df.head()


# Try a small subset
trial_df = test_df.iloc[:10].copy()


#Build prompts
all_prompts = []
for index,row in trial_df.iterrows():
    
    medical_notes = row.Note
    filled_prompt = f"{prompt_template}".replace("{medical_notes}", medical_notes)    
    message=[
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": filled_prompt}
    ]
    all_prompts.append(message)
    


print(all_prompts[0])


def print_outputs(outputs):
    for output in outputs:
        prompt = output.prompt
        generated_text = output.outputs[0].text
        print(f"Generated text: {generated_text!r}")
        print("-" * 80)





%%time
from vllm import SamplingParams
sampling_params = SamplingParams(n=1,
                                 temperature=0.2, 
                                 top_p=0.9,
                                 seed=777, # Seed for reprodicibility
                                 max_tokens=1024,)

from time import time
start = time()

# responses = llm.generate(
#     all_prompts[0],
#     sampling_params,
#     use_tqdm = True
# )

outputs = llm.chat(messages=all_prompts,
                   sampling_params=sampling_params,
                   use_tqdm=True)

end = time()
elapsed = (end-start)/60. #minutes
print(f"Inference took {elapsed} minutes!")


print_outputs(outputs)






def clean_preds(preds:str):
    try:
        preds = preds.split('```json\n')[1].split('\n```')[0]
    except Exception as e:
        
        # print(e)
        try: 
            preds = preds.split('\n\n')[1]
        except Exception as e:
            # print(e)
            preds = preds
 
    return preds


json_list = []

for output in outputs:
    res = output.outputs[0].text
    
    try:
        json_list.append(json.loads(clean_preds(res)))
    except:
        print("Error")
        json_list.append(res)
    
trial_df['json'] = json_list
sub_df = trial_df[['ID','json']]
# test_trial_df.to_csv("test_with_json2_final.csv", index=False)


# take a look at a prediction
sub_df.iloc[2]['json']



